{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import importlib\n",
    "import model\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import tqdm\n",
    "import kan as k\n",
    "import cheby\n",
    "import kalnet as kal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(model)\n",
    "importlib.reload(kal)\n",
    "importlib.reload(k)\n",
    "importlib.reload(cheby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan import KAN\n",
    "from cheby import ChebyKANLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_continual_learning(model, epochs):\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for _ in tqdm.tqdm(range(10)):\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        for epoch in tqdm.tqdm(range(epochs)):\n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "        accuracy = correct / total\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(models, epochs=5):\n",
    "    for model_dict in models:\n",
    "        model_name = model_dict[\"name\"]\n",
    "        model = model_dict[\"model\"]\n",
    "        print(f\"Training model: {model_name}\")\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        accuracies = []\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_loss = 0\n",
    "            for images, labels in tqdm.tqdm(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            train_losses.append(epoch_loss / len(train_loader))\n",
    "\n",
    "            test_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm.tqdm(test_loader):\n",
    "                    outputs = model(images)\n",
    "                    loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "                    test_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            test_losses.append(test_loss / len(test_loader))\n",
    "            accuracies.append(correct / total)\n",
    "\n",
    "            print(\n",
    "                \"Model: {}, Epoch: {}, Train Loss: {:.4f}, Test Loss: {:.4f}, Test Acc: {:.4f}\".format(\n",
    "                    model_name, epoch, train_losses[-1], test_losses[-1], accuracies[-1]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        model_dict[\"train_losses\"] = train_losses\n",
    "        model_dict[\"test_losses\"] = test_losses\n",
    "        model_dict[\"accuracies\"] = accuracies\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_model_metrics(loaded_results):\n",
    "    names = [r['name'] for r in loaded_results]\n",
    "    accuracies = [r['accuracies'] for r in loaded_results]\n",
    "    total_params = [sum(p.numel() for p in model.parameters()) for model in [r['model'] for r in loaded_results]]\n",
    "\n",
    "    colors = ['blue', 'green', 'red', 'purple', 'orange']  # Colors for 5 models\n",
    "\n",
    "    # Plot accuracy comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, name in enumerate(names):\n",
    "        plt.plot(range(1, 11), accuracies[i], label=name, color=colors[i])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Model Accuracy Comparison')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    test_losses = [r['test_losses'] for r in loaded_results]\n",
    "    train_losses = [r['train_losses'] for r in loaded_results]\n",
    "\n",
    "    num_epochs = len(test_losses[0])  \n",
    "    num_models = len(names)\n",
    "    bar_width = 0.15\n",
    "\n",
    "    index = np.arange(num_epochs)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for i in range(num_models):\n",
    "        plt.bar(index + i * bar_width, np.array(train_losses[i]) - np.array(test_losses[i]), bar_width, color=colors[i], label=names[i])\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss Difference (Train - Test)')\n",
    "    plt.title(\"Convergence Speed Comparison\")\n",
    "    plt.xticks(index + bar_width, range(1, num_epochs + 1)) \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot total parameters\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, name in enumerate(names): \n",
    "        plt.bar(name, total_params[i], color=colors[i], label=name)\n",
    "        plt.text(i, total_params[i], str(total_params[i]), ha = 'center', va = 'bottom')\n",
    "\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Total Parameters Comparison')\n",
    "    plt.title('Total Parameters for Each Model')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import GRAMLayer\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 32),\n",
    "            nn.LayerNorm(32),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.LayerNorm(16),\n",
    "            nn.Linear(16, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.layers(x)\n",
    "\n",
    "class GRAM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRAM, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            GRAMLayer(28 * 28, 32), GRAMLayer(32, 16), GRAMLayer(16, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.layers(x)\n",
    "\n",
    "class MNISTChebyKAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTChebyKAN, self).__init__()\n",
    "        self.chebykan1 = ChebyKANLayer(28*28, 32, 4)\n",
    "        self.ln1 = nn.LayerNorm(32)\n",
    "        self.chebykan2 = ChebyKANLayer(32, 16, 4)\n",
    "        self.ln2 = nn.LayerNorm(16)\n",
    "        self.chebykan3 = ChebyKANLayer(16, 10, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # Flatten the images\n",
    "        x = self.chebykan1(x)\n",
    "        x = self.ln1(x)\n",
    "        x = self.chebykan2(x)\n",
    "        x = self.ln2(x)\n",
    "        x = self.chebykan3(x)\n",
    "        return x\n",
    "\n",
    "kalnet = kal.KAL_Net([28*28, 32, 16, 10])\n",
    "\n",
    "kan = KAN([28*28, 32, 16, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    {\"name\": \"KAN\", \"model\": kan},\n",
    "    {\"name\": \"GRAM\", \"model\": GRAM()},\n",
    "    {\"name\": \"Cheby\", \"model\": MNISTChebyKAN()},\n",
    "    {\"name\": \"KALNET\", \"model\": kalnet},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_and_test_model(models, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_metrics(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
